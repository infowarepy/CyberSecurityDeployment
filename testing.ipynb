{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7d92d41",
   "metadata": {},
   "source": [
    "## list out of bound testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21262dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from googlesearch import search\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c7325176",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter1(links,country_name):  \n",
    "    https_links = [link for link in links if 'https://' in link.lower()] \n",
    "    authentic_site_extension = extension_for_url(country_name)\n",
    "    print(\"extension name : \",authentic_site_extension)\n",
    "    com_ex = ['.gov','.org','.eu','itu']\n",
    "    c_ex = [i for i in authentic_site_extension if i not in com_ex]\n",
    "    \n",
    "    first_stage_filter = [link for i in authentic_site_extension for link in https_links if i.lower() in link.lower()]\n",
    "    first_stage_filter = https_links if len(first_stage_filter) == 0 else first_stage_filter\n",
    "    filter1_links = list(set(first_stage_filter))\n",
    "    return filter1_links,c_ex\n",
    "def extension_for_url(country):\n",
    "    df = pd.read_csv(\"WebScrap.csv\")\n",
    "    key =[]\n",
    "    for i in df['Country']:\n",
    "        if country.replace(\" \",'').lower() in i.lower().replace(\" \",''):\n",
    "            x = (df.loc[(df['Country'] == i )]).values.tolist()\n",
    "            url_kwy = [i for i in x[0][1:] if str(i) != 'nan']\n",
    "            key += url_kwy\n",
    "    ke = list(set(key))\n",
    "    return ke\n",
    "def filter_sublinks(sublink_list,main_extension):\n",
    "    df = pd.read_excel(\"Regulator.xlsx\", sheet_name='keywords')\n",
    "    keyword_list = [i for i in df['Url_keywords'].tolist() if str(i) != 'nan']\n",
    "    filter2_sublinks = []\n",
    "    for keyword in keyword_list:\n",
    "        y = keyword.translate(str.maketrans('', '', string.punctuation))\n",
    "        for each_sublink in sublink_list:\n",
    "            if main_extension in each_sublink:\n",
    "                 filter2_sublinks.append(each_sublink)            \n",
    "            x = each_sublink.translate(str.maketrans('', '', string.punctuation))\n",
    "            if y.lower() in x.lower():\n",
    "                filter2_sublinks.append(each_sublink)\n",
    "    filter2_sublinks = list(set(filter2_sublinks))\n",
    "    return filter2_sublinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0bf32d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_responce >>>  cyber security policy/strategy in European Union\n"
     ]
    }
   ],
   "source": [
    "raw_links=[]\n",
    "country_name = ''                                             \n",
    "country_name = 'European Union'\n",
    "user_response = \"cyber security policy/strategy in European Union\"\n",
    "print(\"user_responce >>> \",user_response)\n",
    "for j in search(user_response, tld=\"co.in\", num=1, stop=10, pause=2):     ########\n",
    "    raw_links.append(j)    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e448ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw links >>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ['https://digital-strategy.ec.europa.eu/en/policies/cybersecurity-strategy', 'https://digital-strategy.ec.europa.eu/en/policies/cybersecurity-policies', 'https://www.european-cyber-defence-policy.com/', 'https://www.itgovernance.eu/en-ie/eu-cybersecurity-strategy-ie', 'https://www.gmfus.org/sites/default/files/2021-10/Cyber-Agora-20page-web-02.pdf', 'https://www.swp-berlin.org/10.18449/2021C16/', 'https://www.weforum.org/agenda/2022/12/cybersecurity-european-union-nis/', 'https://www.headmind.com/en/cybersecurity-in-the-eu-european-commissions-strategy-and-legislation/', 'https://blogs.uned.es/digitaleconomy/wp-content/uploads/sites/253/2022/01/Cybersecurity-in-the-EU-an-introduction.pdf', 'https://finabel.org/info-flash-the-development-of-the-eu-cyber-security-strategy-and-its-importance/']\n"
     ]
    }
   ],
   "source": [
    "print(\"raw links >>>>>>>>>>>>>>>>>>>>>>>>>>>>> \",raw_links)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4ba03a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extension name :  ['.org', '.gov', '.eu']\n"
     ]
    }
   ],
   "source": [
    "filter1links,c_ex = filter1(raw_links,country_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e839f20e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'string' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m filter2links \u001b[38;5;241m=\u001b[39m \u001b[43mfilter_sublinks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilter1links\u001b[49m\u001b[43m,\u001b[49m\u001b[43mc_ex\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[17], line 27\u001b[0m, in \u001b[0;36mfilter_sublinks\u001b[1;34m(sublink_list, main_extension)\u001b[0m\n\u001b[0;32m     25\u001b[0m filter2_sublinks \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m keyword \u001b[38;5;129;01min\u001b[39;00m keyword_list:\n\u001b[1;32m---> 27\u001b[0m     y \u001b[38;5;241m=\u001b[39m keyword\u001b[38;5;241m.\u001b[39mtranslate(\u001b[38;5;28mstr\u001b[39m\u001b[38;5;241m.\u001b[39mmaketrans(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43mstring\u001b[49m\u001b[38;5;241m.\u001b[39mpunctuation))\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m each_sublink \u001b[38;5;129;01min\u001b[39;00m sublink_list:\n\u001b[0;32m     29\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m main_extension \u001b[38;5;129;01min\u001b[39;00m each_sublink:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'string' is not defined"
     ]
    }
   ],
   "source": [
    "filter2links = filter_sublinks(filter1links,c_ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8eef767c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extension name :  ['.org', '.gov', '.eu']\n"
     ]
    }
   ],
   "source": [
    "links=raw_links\n",
    "country_name=country_name\n",
    "https_links = [link for link in links if 'https://' in link.lower()] \n",
    "authentic_site_extension = extension_for_url(country_name)\n",
    "print(\"extension name : \",authentic_site_extension)\n",
    "com_ex = ['.gov','.org','.eu','itu']\n",
    "c_ex = [i for i in authentic_site_extension if i not in com_ex]\n",
    "\n",
    "first_stage_filter = [link for i in authentic_site_extension for link in https_links if i.lower() in link.lower()]\n",
    "first_stage_filter = https_links if len(first_stage_filter) == 0 else first_stage_filter\n",
    "filter1_links = list(set(first_stage_filter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "516d671b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.org', '.gov', '.eu']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authentic_site_extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6b032ff0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.gov', '.org', '.eu', 'itu']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "com_ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bab362c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07332608",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be2a062",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c2a0bb51",
   "metadata": {},
   "source": [
    "## metadata script testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "23034843",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pikepdf\n",
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c96d3e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pdf_paths(csv_file):\n",
    "    data = pd.read_csv(csv_file)\n",
    "    pdf_paths = data[\"path\"].tolist()\n",
    "    return pdf_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a6b3eb23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error in Latvia/NDK_ENG_final.pdf\n",
      "error in Czech_Republic/ap-cs-2015-2020-en.pdf\n",
      "error in Czech_Republic/ncss_2015-2020_en.pdf\n",
      "error in Czech_Republic/action_plan_cs_2012-2015_en.pdf\n",
      "error in Slovenia/Cyber_Security_Strategy_Slovenia.pdf\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    csv_file = \"pdf_log.csv\"\n",
    "    pdf_paths = extract_pdf_paths(csv_file)\n",
    "    df=pd.read_csv('metadata.csv')\n",
    "    columns=df.columns\n",
    "    keys=[]\n",
    "    for pdf_filename in pdf_paths:\n",
    "        temp=pdf_filename.split('/')\n",
    "        country=temp[0]\n",
    "        name=temp[1]\n",
    "        data=[country,name]\n",
    "        try:\n",
    "            pdf = pikepdf.Pdf.open(pdf_filename)\n",
    "            docinfo = pdf.docinfo\n",
    "            keys=list(docinfo.keys())\n",
    "            for column in columns:\n",
    "                if f'/{column}' in keys:\n",
    "                    data.append(str(docinfo[f'/{column}']))\n",
    "                else:\n",
    "                    data.append('')\n",
    "            with open(\"metadata.csv\", \"a\",newline='') as f:\n",
    "                writer = csv.writer(f)\n",
    "                writer.writerow(data)\n",
    "        except:\n",
    "            print(f'error in {pdf_filename}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "71899f8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Latvia'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_paths[0].split('/')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622cc367",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"metadata.csv\", \"a\",newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa71994",
   "metadata": {},
   "outputs": [],
   "source": [
    "docinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4639c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97920dba",
   "metadata": {},
   "source": [
    "## PDF Content comparison testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e90ebd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843f982f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path='Australia/PMC-Cyber-Strategy.pdf'\n",
    "read_pdf = PyPDF2.PdfReader(path)\n",
    "pdf_content=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ce768d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_content = lambda read_pdf: ''.join([page.extract_text().replace(\"\\n\", ' ').lower() for page in read_pdf.pages])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fb1080",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf1=pdf_content(read_pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60484c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "content=''\n",
    "for page in read_pdf.pages:\n",
    "    content+=(page.extract_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f49b935",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pdf1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa094e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(read_pdf.pages[0].extract_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb488fd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8dc0ff2c",
   "metadata": {},
   "source": [
    "# Runtime calculation error testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c97b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import pandas as pd\n",
    "import string\n",
    "import requests\n",
    "import time \n",
    "import datetime\n",
    "from duplicate_text_extractor_from_link import *\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from pdf_selector_update1 import *\n",
    "import pytz\n",
    "import csv\n",
    "\n",
    "from googlesearch import search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257b36c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_time_taken(start_time_str, end_time_str):\n",
    "    parse=lambda time : datetime.datetime.strptime(time, '%H:%M:%S.%f')\n",
    "    start_time = parse(start_time_str)\n",
    "    end_time = parse(end_time_str)\n",
    "    time_taken = end_time - start_time\n",
    "    return time_taken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e93261",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_dir = 'summary.txt'\n",
    "with open(text_dir,'a') as document:\n",
    "    df = pd.read_csv('test_country.csv')\n",
    "    for cnt in range(len(df[\"Country_Name\"])):\n",
    "        start_time=str(datetime.datetime.now()).split()[1]\n",
    "        date=start_time.split()[0]\n",
    "        raw_links=[]\n",
    "        country_name = ''\n",
    "        user_response = df[\"Country_Name\"][cnt]                                               \n",
    "        country_name = user_response\n",
    "        user_response = \"cyber security policy/strategy in \"+user_response\n",
    "        print(\"user_responce >>> \",user_response)\n",
    "        \n",
    "#         for j in search(user_response, tld=\"co.in\", num=1, stop=10, pause=2):     ########\n",
    "#             raw_links.append(j)    \n",
    "        raw_links=['https://www.bundeskanzleramt.gv.at/dam/jcr:537d3bae-ffed-4d49-803b-524d304b7972/islamgesetz_2015_tuerkisch_gesetzestext.pdf']\n",
    "        print(\"raw links >>>>>>>>>>>>>>>>>>>>>>>>>>>>> \",raw_links)\n",
    "        \n",
    "        links=raw_links\n",
    "        end_time=str(datetime.datetime.now()).split()[1]\n",
    "        total_runtime=calculate_time_taken(start_time,end_time)\n",
    "        log_data = [str(country_name), date, start_time, end_time, total_runtime, str(links), str(len(links))]\n",
    "\n",
    "        with open(\"logdet.csv\", \"a\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(log_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aefb829",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc198bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5914b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe26c6f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdadc0ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871dbd30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9f4aa0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39882296",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "310c6051",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"Regulator.xlsx\", sheet_name='keywords')\n",
    "keyword_list = [i for i in df['content_keywords'].tolist() if str(i) != 'nan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fd085b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Url_keywords</th>\n",
       "      <th>content_keywords</th>\n",
       "      <th>pdf_basic_keyword</th>\n",
       "      <th>word_frequency_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cybersecurity</td>\n",
       "      <td>national</td>\n",
       "      <td>regulation</td>\n",
       "      <td>Security-35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cybersecurity-act</td>\n",
       "      <td>cyber</td>\n",
       "      <td>law</td>\n",
       "      <td>Information-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cyber</td>\n",
       "      <td>secuirty</td>\n",
       "      <td>policy</td>\n",
       "      <td>Cyber/IT-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>security</td>\n",
       "      <td>policy</td>\n",
       "      <td>government</td>\n",
       "      <td>National-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>policy</td>\n",
       "      <td>regulator</td>\n",
       "      <td>risk</td>\n",
       "      <td>Act-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>NaN</td>\n",
       "      <td>trade</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>NaN</td>\n",
       "      <td>banking</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>NaN</td>\n",
       "      <td>insurance</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>NaN</td>\n",
       "      <td>market</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>NaN</td>\n",
       "      <td>defence</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Url_keywords content_keywords pdf_basic_keyword word_frequency_count\n",
       "0       cybersecurity         national        regulation          Security-35\n",
       "1   cybersecurity-act            cyber               law       Information-10\n",
       "2               cyber         secuirty            policy          Cyber/IT-30\n",
       "3            security           policy        government           National-5\n",
       "4              policy        regulator              risk                Act-3\n",
       "..                ...              ...               ...                  ...\n",
       "57                NaN            trade               NaN                  NaN\n",
       "58                NaN          banking               NaN                  NaN\n",
       "59                NaN        insurance               NaN                  NaN\n",
       "60                NaN           market               NaN                  NaN\n",
       "61                NaN          defence               NaN                  NaN\n",
       "\n",
       "[62 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ac8adc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_pdf_keywords = [i for i in df['pdf_basic_keyword'].tolist() if str(i) != 'nan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af92081a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['regulation',\n",
       " 'law',\n",
       " 'policy',\n",
       " 'government',\n",
       " 'risk',\n",
       " 'access',\n",
       " 'system',\n",
       " 'data']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_pdf_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3958806",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd713e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_link='https://www.bundeskanzleramt.gv.at/dam/jcr:537d3bae-ffed-4d49-803b-524d304b7972/islamgesetz_2015_tuerkisch_gesetzestext.pdf'\n",
    "headers = { 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36' } \n",
    "response = requests.get(pdf_link, headers = headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fac9a06c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9aa6125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "requests.models.Response"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e78717a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_raw_data=response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f92cb0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "import PyPDF2\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2cc17944",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_content = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9894e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with BytesIO(my_raw_data) as data:\n",
    "    read_pdf = PyPDF2.PdfReader(data)\n",
    "    pages_text1 = read_pdf.pages[0].extract_text()\n",
    "    pages_text2 = read_pdf.pages[1].extract_text()\n",
    "    # print(\"pages text >>>>>>>>>. \",pages_text)\n",
    "    for page in range(len(read_pdf.pages)):\n",
    "        each_page_content = read_pdf.pages[page].extract_text()\n",
    "        text = each_page_content.replace(\"\\n\",' ').lower()\n",
    "        pdf_content += text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c176ed67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1   uyarı: bu tercüme olabilecek en büyük özenle hazırlanmıştır. tercüme ile  almanca metin  arasında uyumsuzluk veya çelişkiler bulunması halinde yalnızca almanca metin doğru ve  hukuken geçerlidir.    i̇slâm din topluluklarının harici hukuk i̇lişkileri hak kında federal yasa çıkarmak  için federal yasa   millî meclis kararlaştırdı:   i̇slâm din topluluklarının harici hukuk i̇lişkileri hakkında federal yas a  – i̇slâm yasası 2015     1. bölüm   hukuki statü   kamu kuruluşu   madde 1 – avusturya’daki i̇slâm din toplulukları “vatandaşların te mel haklarına i̇lişkin  anayasa’nın” (“staatsgrundgesetz” -1867 anayasasının)  15. maddesi gereğince resmen  kabul edilmiş din topluluklarıdır. onlar kamu kuruluşudur.   özerklik   madde 2 – (1) i̇slâm din toplulukları dâhili meselelerini düzenle me ve yönetimlerinde  özerktirler. i̇nançları ve öğretileri açısından özgürdürler ve dinl erini kamuya açık  yaşayabilirler.   (2) i̇slâm din toplulukları diğer resmen tanınmış din topluluklarıyl a aynı yasal korumaya  haizdir. yasal düzenlemelere aykırılık teşkil etmemek kay dıyla dinî öğretileri, kurumları  ve adetleri de koruma altındadır. din toplulukları, dinî cemaatl er ve diğer yapılanmalar  ile üyeleri temel devlet kurallarına uyulması konusunda - uygulan acak ilgili devlet  kanunları böyle bir olanak sunmadığı sürece - dinî topluluklarının iç k urallarını veya  öğretilerini dayanak gösteremezler.   tüzel kişilik kazanma   madde 3 – (1) bu federal yasaya göre kurulmuş i̇slâm din toplulukl arı tüzel kişiliklerini  müracaat üzerine federal başbakanın yönergesiyle kazanırlar. yöner ge, 3. ve 4. bölüm  hükümlerinin hangi koşullarda dinî topluluklara uygulanacağını içermelidir .  i̇dari  yargılama usulü kanunu’nun (verwaltungsgerichtsverfahrensgesetz  – vwgvg ) 8. 2   maddesinde tanınan mühlet, başvurunun olası düzeltilmesi ve tarafla rın olası dinlenmesi  açısından, düzeltme emrinin veya kişilerin dinlenmesi için dave tiye gönderildiği tarihten  itibaren düzeltmenin veya görüşün intikal etmesi veya bunlar için v erilen mühletin sona  ermesine kadar askıya alınır.   (2) federal başbakan, 1.fıkra doğrultusunda intikal eden başvurular ı internet ortamında  din i̇şleri dairesinin (“kultusamt”) görev alanına ilişkin kur ulacak olan web sitesinde  kamuya açık biçimde yayınlamalıdır.   (3) tüzel kişiliğin kazanılmasına ilişkin, i̇slâm din topluluğun un ismini ve topluluğu dış  temsile yetkili olan organların genel isimlerini içeren bir ka rar çıkarılmalıdır.   (4) 3. fıkra doğrultusunda tüzel kişiliğin kazanılmasıyla birli kte, ilgili din topluluğunun  din öğretilerini yayma amacı güden dernekler lağvedilmelidir.   (5) bir i̇slâm din topluluğu, ilgili dinî inancı destekleme amaçlı  bir derneğin  lağvedilmesiyle yeniden kuruluyor ise, vergiler açısından sadece hukuki statü  değişikliğinin gerçekleştiği ve aynı mükellefin (yasal sorumlu) varlığını sürdürdüğü  varsayılmalıdır.   tüzel kişiliğin kazanılmasına i̇lişkin şartlar   madde 4 – (1) bir i̇slâm din topluluğunun bu federal yasa hükümlerine göre bir tüzel  kişilik kazanabilmesi için, kalıcılığı güvence altında olmalı  ve ekonomik varlığını kendi  kendine idame ettirebilmelidir. kalıcılığın güvence altında olma sı için başvuru sahibi  resmi kayıtlı bir dinî mezhep topluluğu olmasının yanında son nüfus sayım ına göre  belirlenen avusturya nüfusunun en az binde ikisi kadar üye sayısına sa hip olmalıdır.  bunu kanıtlamak ise başvuru sahibinin sorumluluğundadır.   (2) gelirler ve mal varlığı yalnızca dinî amaçlar için kul lanılabilir. dinî amaçlara, dinî  hedefler doğrultusundaki hayırsever ve kamu yararına olan amaçlar  da dâhildir.   (3) toplum ve devlete karşı olumlu bir temel tutum sergilenmel idir.   (4) resmen tanınmış mevcut kiliseler ve din toplulukları ile diğer din topluluklarına  bulunan ilişkilerde yasaya aykırı bir uygunsuzluk bulunmamalıdır.   tüzel kişiliğin reddi ve i̇ptali   madde 5 – (1) federal başbakan, tüzel kişilik talebini aşağıda ki durumlarda  reddetmelidir:   1. (talep sahibi topluluğun) öğreti veya öğretinin uygulanması yönünden demokratik bir  toplumun kamu emniyeti, nizamı, esenliği ve ahlakı gibi menfaatl erinin veya diğer  fertlerin hak ve özgürlüklerinin korunması lüzumunu doğruyor ise. 3   bunlar bilhassa, ceza gerektiren yasaya aykırı davranışlar a teşvik, yetişmekte olan  çocukların psikolojik gelişimini engellemek, psikolojik bütünlüğün za rar görmesi ve –  özellikle inanç aktarımı amacıyla – psikoterapi metotlarını n uygulanması.   2. madde 4 gereği şartlardan biri eksik ise,   3. tüzükleri 6. maddeye aykırı ise   (2) aşağıdaki durumlarda, din topluluğunun tanınmasını federal devlet yöne rge ile  kaldırmalıdır; bir din topluluğunun tüzel kişiliğini ise federal baş bakan kararla  kaldırmalıdır:   1. üye sayısı hariç, 4. veya 8. madde gereğince hukuki statü kazanımı için önemli bir  şartın artık mevcut olmaması,   2. eğer 1. fıkra gereği bir ret nedeni mevcut ise ve statü iptaline neden olan durumun  giderilmesi istenmesine rağmen durumun devam etmesi halinde,   3.topluluk veya cemaat tüzüklerine aykırı bir davranışın durdurul ması istenmesine  rağmen davranışın devam etmesi veya   4. resmen tanınmaya istinaden oluşan yükümlülüklerin yerine getiril mesi istenmesine  rağmen bunların yerine getirilmemesi.   (3) tüzel kişiliğin iptaline dair yönergenin ilamından sonra üç iş günü içerisinde  gerekçelere ilişkin bir tespit kararı (“feststellungsbesche id”) çıkarılmalıdır. bu tespit  kararı din topluluğunun ve en son dış temsile yetkisi bulunan organları nın ismini  içermeli ve bunlara tebliğ edilmelidir.   (4) hukuki statünün reddi veya iptali, internet ortamında din i̇şl eri dairesinin  (“kultusamt”) görev alanına ilişkin kurulacak olan web sitesinde kamuya açık biçimde  yayınlamalıdır.   2. bölüm   kurumsal yapı ve görevler   i̇slâm din topluluklarının tüzükleri   madde 6 – (1) bir i̇slâm din topluluğunun dâhili meseleleri çerçeve sinde hazırlanan  tüzüğün, resmi geçerliğini sağlamak üzere aşağıdaki bilgileri re smi dilde içermelidir:   1. i̇sim ve kısaltması - ancak din topluluğu açıkça teşhis edi lebilir olmalı ve başka  kiliseler veya din toplulukları, dernekler, kurumlar veya ba şka hukuki statülerle  karıştırılması olanaksız olmalıdır;  4   2. din topluluğunun merkezi;   3. üyeliğin kazanılması ve kaybı;   4. üyelerin hak ve yükümlülükleri;   5. temel inanç kaynaklarının (kur’an-ı kerim) bir metni dâhil  olmak ve diğer mevcut,  resmen tanınmış din topluluklarının, mezhep topluluklarının veya din  topluluklarınınkinden farklı olmak kaydıyla dinî öğretinin sunumu;   6. dâhili teşkilatlanma - burada en azından dinî cemaatler ön görül melidir;   7. din topluluğu içerisinde mevcut bütün mezheplerin uygun biçimde gözetilm esi;   8. organların atanma şekli, görev süresi ve azli;   9. din dersinin tedarik şekli ve bunun denetimi;   10. kaynakların sağlanması, bunların idaresi ve muhasebesi;   11. din topluluğu içerisinde oluşan tartışmaların uzlaşıyla sonuçlandı rılması;   12. tüzük oluşturma ve değişiklikler yapılması.   (2) üyelerinin dinî ihtiyaçlarını karşılama amacı taşıyan ol ağan faaliyetler için kaynakların  sağlanması, din topluluğu, dinî cemaatleri veya ülke içindeki üyele ri tarafından  gerçekleştirilmelidir.   bir din topluluğunun görevleri   madde 7 – bir din topluluğunun görevleri özellikle:   1. bir dinî cemaatin etki alanını aşması halinde, üyelerinin çı karlarını korumak; (bu  bağlamda)  din toplulukları üst makamdır;   2. din toplulukları ve dinî cemaat tüzüklerinin ve bunlardaki değişik liklerin yanı sıra  organlarının terkibinde meydana gelen değişiklikleri federal başbaka na ibraz etmek;   3. din topluluğunun dâhili hukukuna göre tüzel kişilik kazanmış olan kuruluş ların, resmi  olarak da tüzel kişiliğe haiz olabilmeleri için bunların ve bunla rı temsil yetkisine sahip  organ ve organ idaresi ile bunlarda meydana gelen değişiklikleri fede ral başbakana  ibraz etmek.   dinî cemaatler (“kultusgemeinden”)   madde 8 – (1) dinî cemaatler aynı zamanda özerk kamu kuruluşla rı olan i̇slâm din  topluluklarının parçalarıdır. üyelerinin dinî ihtiyaçlarını karşıl amak ve bunun için gerekli  tesisleri sağlamakla mükelleftir.  5   (2) dinî cemaatler 1. fıkrada belirtilen görevleri yerine getirmek üzere tesisler kurabilir,  yönetebilir ve mevcut tesisleri dinî cemaat tesisi olarak tayin edebilirler. birkaç dinî  cemaatin kuracağı ortak tesisler ise ancak bütün tarafların m utabakatı ve din  topluluğunun muvafakati ile kurulabilir.   (3) dinî cemaatler ancak, kalıcılıkları ve ekonomik var lıklarını kendi kendine idame  ettirme kabiliyetleri güvenceye alındığı takdirde ve din topluluğunu n muvafakatiyle  kurulabilirler.   (4) her dinî cemaatin bir tüzüğü bulunmalı ve resmi geçerliğini sağlamak üzere  aşağıdaki bilgileri içermelidir:   1. dinî cemaatin ismi ve kısaltması - ancak din topluluğu açı kça teşhis edilebilir olmalı ve  başka kiliseler veya din toplulukları, dernekler, kurumlar, dinî  cemaatler veya başka  hukuki statülerle karıştırılması olanaksız olmalıdır;   2. dinî cemaatin merkezi;   3. üyeliğin kazanılması ve kaybına ilişkin düzenlemeler;   4. üyelerin hak ve yükümlülükleri;   5. dâhili teşkilatlanmaya ilişkin, özellikle üyelik kayı tlarına ilişkin düzenlemeler;   6. cemaat organlarının atanma şekli, görev süresi ve azline  ilişkin düzenlemeler;   7. kaynakların sağlanması, bunların idaresi ve muhasebesine iliş kin düzenlemeler;   8. dinî cemaatler içerisinde oluşan tartışmaların uzlaşıyla  sonuçlandırılmasına ilişkin  düzenlemeler ve   9. tüzük oluşturulması ve değişiklik yapılmasına dair düzenlemele r.   (5) bir dinî cemaatin lağvedilmesi halinde, en son görevde olan organla r, mal varlı ğı  hakkında din topluluğu ile mutabakat içinde karara varmalıdırlar .   3. bölüm   “avusturya i̇slâm cemaati’nin” hak ve yükümlülükleri   i̇sim hakkı ve dinî terimlerin korunması   madde 9 – (1) din topluluğu, 6. madde 1. fıkra 1. satırda belirt ilen sınırlar çerçevesinde  bir isim seçme hakkına sahiptir.   (2) din topluluğunun ve dinî cemaatlerin isimleri ve bunlardan türeti len bütün terimler  yalnızca din topluluğunun veya dinî cemaatin izniyle kullanılabilir.  6   (3) yabancı üçüncü kişilere, avusturya dışında bulunan, din topluluğunun münferit   kurumlarına, bir dinî cemaate veya benzer kurumlara hukuki bir bağı n bulunduğu  izlenimini vermeye yönelik terimler, yalnızca din topluluğunun iz niyle kullanılabilir.   (4) bu hükümlerin ihlali durumlarında - eğer ceza mevzuatı hükümleri  uygulanmıyor ise  - din toplulukları ve ilgili her dinî cemaat yasadışı durumun sonlandır ılması istemiyle  federal başbakana bir dava süreci başlatılması dilekçesiyle başvurabilir. başvuru dört  hafta içerisinde karara bağlanmalıdır.    i̇nceleme hakkı   madde 10 – (1) din topluluğu, yasama ve her seviyedeki idare orga nlarına, resmen  tanınmış kilise ve din topluluklarına ilişkin bilirkişi raporla rı, görüş, rapor ve öneri iletme  hakkına sahiptir.   (2) din topluluğunun harici hukuk ilişkileri hakkında alınan yasal t edbirler ibrazlarından  önce, düzenlemeler de çıkartılmadan önce, din topluluğuna uygun bir mühlet  tanınarak  görüş bildirebilmesi için iletilmelidir.   özel kurumlar ve gençlik eğitiminde dinî rehberlik sunma  hakkı   madde 11 – (1) üyeleri   1. federal silahlı kuvvetler mensubu olan veya   2. mahkemece veya idarece tutuklu bulunan veya   3. devlet hastanesi, bakım evi, huzur evi veya benzeri kurumla rda bulunan   din topluluğu, bunlara dinî rehberlik sunma hakkına sahiptir.   (2) 1. fıkradaki hizmetler, ancak eğitimlerini avusturya’da almış olmaları ve yaşamlarını  avusturya’da sürdürmeleri nedeniyle profesyonel ve kişisel olarak  buna uygun kişilerce  yerine getirilebilir. bütün mezhep hususlarında din topluluğuna bağlıdırlar,  diğer bütün  hususlarda ise kurumun ilgili yönetimine bağlıdırlar. sadece, 24. m adde gereği bir  üniversite mezunu veya eşdeğer bir kalifikasyona sahip olunduğu takdir de profesyonel  yeterlik söz konusudur. kişisel yeterlik ise ilgili alanda as gari 3 yıllık meslek tecrübesi ve  lise mezuniyeti seviyesinde almanca bilgisine vakıf olmayı ger ektirir. bunun yanı sıra din  topluluğundan yetkilendirme gerekmektedir.   (3) 1. fıkra 1. satırda anılan hizmetlerin sağlanabilmesi i çin gerekli ayni ve personel  ihtiyaçlar federal devlet tarafından karşılanmalıdır.   (4) din topluluğu ve üyeleri, çocuklara ve gençlere bütün mezhepsel görenekleri  öğretmeye ve onları dinî vecibelere göre yetiştirme hakkına sa hiptir.  7   gıda kuralları   madde 12 – (1) din topluluğu, avusturya’da et ürünleri ve başkaca gıda ların üretimini  kendi dinî kurallarına göre organize etme hakkına sahiptir.   (2) federal silahlı kuvvetlere mensup veya ceza evlerinde, devlet hastanelerinde bakım  ve huzur evleri veya benzer kurumlarda ve devlet okullarında buluna n din topluluğu  üyelerinin beslenmesinde dinî gıda kuralları gözetilmelidir.   dinî tatiller   madde 13 – (1) dinî tatiller ve cuma namazı saatleri devl etin koruması altındadır. tarih  ve saatleri ise i̇slâmi takvime göre düzenlenir. bir gün, gün batı mından başlayarak bir  sonraki gün batımına kadar sürmektedir. cuma namazı 12.00 – 14. 00 saatleri  arasındadır.   (2) dinî tatiller:    a) ramazan bayramı (3 gün)    b) kurban bayramı (4 gün)    c) aşure günü (1 gün)   (3) 2. fıkrada anılan günlerde ve cuma namazı esnasında mescitl er (“kultstätten”) ve dinî  cemaatlerin başkaca ibadet amaçlı mekân ve binalarında, ibade t ve törenleri etkileyecek,  engellenebilen gürültülü davranışlar ile kamusal toplantı, yürüyüş ve  alaylar yasaktır.   yetki sahiplerin azli   madde 14 – dinî yetkililer dâhil olmak üzere, yetki sahipler i ulusal bir mahkeme  tarafından bir veya birden fazla müteammiden işlenmiş cezai eylemlerden dolayı bir  yıldan daha uzun bir süre için hapis cezasına mahkûm edilmiş veya da vranışları  nedeniyle kamu emniyetini, nizamını, esenliğini ve ahlakını veya  diğer fertlerin hak ve  özgürlüklerini kalıcı bir şekilde tehdit ediyorlar ise, din toplul ukları ve dinî cemaatler bu  kişileri görevlerinden azletmelidir.   mezarlıklar   madde 15 – (1) mezarlıklar veya mezarlık bölümleri kalıc ı bir biçimde düzenlenmiştir.  bunların kaldırılması veya kapatılması ve münferit mezarlar ın kazılması yasaktır.  i̇stisnalar üst makam olan din topluluğunun iznini gerektirir.   (2) mezarlıklar veya mezarlık bölümlerinde cenazeler ancak  üst makam olan din  topluluğunun izniyle gerçekleştirilebilir.  8   4. bölüm   “avusturya alevi i̇slâm cemaati’nin” hak ve yükümlülükleri   i̇sim hakkı ve dinî terimlerin korunması   madde 16 – (1) din topluluğu, 6. madde 1. fıkra 1. satırda belir tilen sınırlar çerçevesinde  bir isim seçme hakkına sahiptir.   (2) din topluluğunun ve dinî cemaatlerin isimleri ve bunlardan türe tilen bütün terimler  yalnızca din topluluğunun veya dinî cemaatin izniyle kullanılabilir.   (3) yabancı üçüncü kişilere, avusturya dışında bulunan, din topluluğunun münferit   kurumlarına, bir dinî cemaate veya benzer kurumlara hukuki bir bağı n bulunduğu  izlenimini vermeye yönelik terimler yalnızca din topluluğunun izni yle kullanılabilir.   (4) bu hükümlerin ihlali durumlarında - eğer ceza mevzuatı hükümleri  uygulanmıyor ise  - din toplulukları ve ilgili her dinî cemaat yasadışı durumun sonlandır ılması istemiyle  federal başbakana bir dava süreci başlatılması dilekçesiyle başvurabilir. başvuru dört  hafta içerisinde karara bağlanmalıdır.   i̇nceleme hakkı   madde 17 – (1) din topluluğu, yasama ve her seviyedeki idare orga nlarına, resmen  tanınmış kilise ve din topluluklarına ilişkin bilirkişi raporla rı, görüş, rapor ve öneri iletme  hakkına sahiptir.   (2) din topluluğunun harici hukuki ilişkileri hakkında alınan yasal tedbirler ibrazlarından  önce, düzenlemeler de çıkartılmadan önce, din topluluğuna uygun bir mühlet  tanınarak  görüş bildirebilmesi için iletilmelidir.    özel kurumlar ve gençlik eğitiminde dinî rehberlik sunma  hakkı   madde 18 – (1) üyeleri   1. federal silahlı kuvvetler mensubu olan veya   2. mahkemece veya idarece tutuklu bulunan veya   3. devlet hastanesi, bakım evi, huzur evi veya benzeri kurumla rda bulunan   din topluluğu, bunlara dinî rehberlik sunma hakkına sahiptir.   (2) 1. fıkradaki hizmetler, ancak eğitimlerini avusturya’da almış olmaları ve yaşamlarını  avusturya’da sürdürmeleri nedeniyle profesyonel ve kişisel olarak  buna uygun dedeler, 9   babalar ve analar tarafından yerine getirilebilir. bütün mezhep husus larında din  topluluğuna bağlıdırlar, diğer bütün hususlarda ise kurumum ilgili yönetim ine  bağlıdırlar. sadece, 24. madde gereği bir üniversite mezunu veya e şdeğer bir  kalifikasyona sahip olunduğu takdirde profesyonel yeterlik söz konusudur. k işisel  yeterlik ise ilgili alanda asgari 3 yıllık meslek tecrübe si ve lise mezuniyeti seviyesinde  almanca bilgisine vakıf olmayı gerektirir. bunun yanı sıra din topl uluğundan  yetkilendirme gerekmektedir.   (3) 1. fıkra 1. satırda anılan hizmetlerin sağlanabilmesi i çin gerekli ayni ve personel  ihtiyaçlar federal devlet tarafından karşılanmalıdır.   (4) din topluluğu ve üyeleri, çocuklara ve gençlere bütün mezhepsel görenekleri  öğretmeye ve onları dinî vecibelere göre yetiştirme hakkına sa hiptir.   gıda kuralları   madde 19 – (1) din topluluğu, avusturya’da et ürünleri ve başkaca gıda ların üretimini  kendi dinî kurallarına göre organize etme hakkına sahiptir.   (2) federal silahlı kuvvetlere mensup veya ceza evlerinde, devlet hastanelerinde, bakım  ve huzur evleri veya benzer kurumlarda ve devlet okullarında buluna n din topluluğu  üyelerinin beslenmesinde dinî gıda kuralları gözetilmelidir.   dinî tatiller   madde 20 – (1) dinî tatiller ve ibadetler (perşembe günleri cem töreni, lokma günleri)  devletin koruması altındadır. tarih ve saatleri ise i̇slâmi takvime göre düzenlenir. bir gün,  gün batımından başlayarak bir sonraki gün batımına kadar sürmektedir.   (2) dinî tatiller:    a) hz. hızır orucu ve bayramı (3 gün)    b) hz. ali’nin doğum günü (1 gün)    c) hz. ali’nin hz. muhammed’in halefi ilanı (1 gün)   d) kurban bayramı (4 gün)   e) aşure günü (1 gün)   (3) 2. fıkrada anılan günlerde ve ibadetler esnasında cem evle ri (“kultstätten”) ve dinî  cemaatlerin başkaca ibadet amaçlı mekân ve binalarında, ibade t ve törenleri etkileyecek,  engellenebilen gürültülü davranışlar ile kamusal toplantı, yürüyüş ve alaylar yasaktır.    10   yetki sahiplerin azli   madde 21 – dinî yetkililer dâhil olmak üzere, yetki sahipler i ulusal bir mahkeme  tarafından bir veya birden fazla müteammiden işlenmiş cezai eylemlerden dolayı bir  yıldan daha uzun bir süre için hapis cezasına mahkûm edilmiş veya da vranışları  nedeniyle kamu emniyetini, nizamını, esenliğini ve ahlakını vey a diğer fertlerin hak ve  özgürlüklerini kalıcı bir şekilde tehdit ediyorlar ise, din toplul ukları ve dinî cemaatler bu  kişileri görevlerinden azletmelidirl.   mezarlıklar   madde 22 – (1) mezarlıklar veya mezarlık bölümleri kalıc ı bir biçimde düzenlenmiştir.  bunların kaldırılması veya kapatılması ve münferit mezarlar ın kazılması yasaktır.  i̇stisnalar üst makam olan din topluluğunun iznini gerektirir.   (2) mezarlıklar veya mezarlık bölümlerinde cenazeler ancak  üst makam olan din  topluluğunun izniyle gerçekleştirilebilir.   5. bölüm   din toplulukları i̇le devletin etkileşimi   din topluluğu kararlarının hukuki geçerlikleri   madde 23 – (1) din topluluğu ve dinî cemaat tüzükleri ile, bunların içinde yer alan ve   dayanağı bulunan usul düzenlemeleri - özellikle din vergisi düzenlemesi  ve seçim  düzenlemesi ve bunların değişikliği - geçerlik kazanabilmeleri i çin federal başbakanın  onayını gerektirirler.   (2) tüzükler gereği dış temsile yetkili organlar ve din görevli leri seçimlerinden veya  atanmalarından sonra din topluluğu tarafından (madde 7 fıkra 2) derhal f ederal  başbakana bildirilmelidirler.   (3) 1. fıkra gereğince yetkili olan organlara ilişkin yapılan değişiklikler ve atamalar ancak  federal başbakanın onayladığı gün itibariyle yürürlüğe girerler. bunlar , federal başbakan  tarafından internet ortamında din i̇şleri dairesinin (“kultusamt” ) görev alanına ilişkin  kurulacak olan web sitesinde kamuya açık biçimde yayınlanmalıdır .  (4) din topluluğunun dâhili hukukuna göre tüzel kişilik kazanmış kurum lar, din  topluluğunun buna ilişkin bildirimi federal başbakana intikal ettiği  gün itibariyle resmi  tüzel kişilik kazanırlar. başbakan bu bildirimi, intikalinden sonr a yazılı olarak  onaylamalıdır. bildirimde tüzel kişiliğin etki alanı ve resmi  olarak temsil ettiği kişileri  içermelidir.  11   i̇lahiyat eğitimi   madde 24 – (1) federal devlet, 1 ocak 2016 tarihinden itibar en, ilahiyat araştırmaları ve  eğitimi ile i̇slâm din topluluklarının yeni ilahiyatçı nesiller inin bilimsel eğitimleri için  viyana üniversitesinde ilahiyat eğitimi sağlamalıdır. bunun için t oplamda altı eğitim  personeline kadar boş kontenjan ön görülmelidir.   (2) bu federal yasa gereği kurulmuş her din topluluğu için üniversitede ayrı bir dal  öngörülmelidir.   (3) 1. fıkrada belirtilen eğitim personeli olarak, üniversite  kanununun 108. maddesi 3.  fıkrası gereğince üniversite çalışanları toplu iş sözleşmesi anlamınca üniversite  profesörleri, üniversite doçentleri, özel doçentler ve yardımcı doçentler uygundur.   (4) 1. fıkrada anılan kontenjanlar için personel alınmadan önce öngörül en kişiye ilişkin  din topluluğun görüşü alınmalıdır; teolojik esas açısından ise, bu federa l yasa hükümleri  gereğince resmen tanınmış din topluluklarının dinî öğretisine (mezhebine)  mensup bir  kişi olmasına dikkat edilmelidir.   i̇hbar ve bildirim yükümlülükleri   madde 25 – din topluluğu ve cumhuriyet, bu federal yasayı ilgilendi ren bir olay  hakkında diğer tarafı bilgilendirmekle yükümlüdür. bu, özellikle dav aların açılması ve  sonlandırılması, 14. ve 21. maddelerde anılan kişiler hakkında mahkûmiyet kararı  verilmesi ve din topluluğunun veya bir dinî cemaatin kendi içlerind e gerçekleştirdikleri  seçimlere karşı yasal araçları kapsar.   gizlilik i̇lkesinin korunması   madde 27 – (1) bu husus için mevcut diğer hükümler saklı kalmak kaydıyla, dinî yetkililer  kendilerine görevlerinin gizlilik ilkesi çerçevesinde aktarıl an konular hakkında şahit  olarak sorgulanamazlar.   (2) 1. fıkra hükümleri aynı zamanda medeni hukuk davalarında kendi lerinden bilgi  alınması veya taraf olarak dinlenmeleri açısından da geçerli dir.   etkinliklerin yasaklanması   madde 27 – i̇dare, kamu emniyeti, nizamı veya esenliği veya millî güvenlik veya diğer  fertlerin hak ve özgürlükleri için doğrudan bir tehlike oluşabileceği  kanaatindeyse dinî  amaçlı toplantı ve etkinlikleri yasaklayabilir. etkinlik  nedeniyle üçüncü kişiler tarafından  oluşabilecek tehlikeler ise yasaklama nedeni değildir.   12     seçimler   madde 28 – (1) dış temsile yetkili olan organlar veya din gör evlileri seçimle belirleniyor  ise seçim süreci, tüzüklerde veya bir seçim yönetmeliğinde, s eçimin denetimini mümkün  kılacak yeterlikte belirlenmiş olması gerekmektedir.   (2) dış temsile yetkili olan organlar veya din görevlileri seçimle belirleniyor ise her fiili  seçim hakkı bulunan veya her, 1.fırkada anılan seçim kuralları  gereği fiili seçim hakkına  sahip olabilecek kişiler, din topluluğu içerisindeki olanaklar tükendi kten sonra federal  başbakana seçim itirazında bulunma hakkına sahiptir.   (3) seçim sonucu ilamı intikal etmesinden itibaren 14 gün içeris inde, din topluluğunun  dâhili hukuku çerçevesinde bir yasal süreç başlatıldığına dair bildi rim gelmediği veya 2.  fıkra gereğince bir itirazda bulunulmadığı takdirde federal başbakan seçim sonucunu  kabul etmeli ve seçim sonucu ilamını yazılı olarak onaylamalı dır.  mütevelli tayini   madde 29 – (1) din topluluğunu veya dinî cemaatini dış temsile ye tkisi bulunan  organların görev süresi asgari altı ayı geçmiş veya başka bir  nedenden dolayı faaliyet  gösteremiyorsa idare, ilgili dinî cemaatten ve din topluluğundan, asga ri bir, azami altı  aylık bir süre içerisinde öngörülen seçimlerin gerçekleştirilme sini veya faaliyet  kabiliyetinin tüzüklere uygun, başka bir şekilde yeniden tesis edil mesini talep etmelidir.   (2) dinî cemaat veya din topluluğu, emri yerine getirmediği ve , ne dinî cemaat ne de din  topluluğu ilgili mahkemede bir mütevelli tayini talebinde bulunmadığı t akdirde, bu  talebi ilgili mahkemeye federal başbakan iletmelidir.   i̇dari hükümlerin uygulanması   madde 30 - bu yasa gereğince alınan kararların uygulanması konusunda i dare, bir  kararla yasaya veya tüzüklere aykırı kararları iptal e debilir, uygun miktarda para cezasına  çarptırabilir ve başkaca hukuken öngörülmüş araçlar kullanabilir.   6. bölüm   son hükümler   mevcut din toplulukları, dinî cemaatler ve bunların tü zükleri   madde 31 – (1) avusturya i̇slâm cemaati (466/1988 sayılı federal resmi gazete[bgbl.])  ve avusturya alevi i̇slâm cemaati (133/2013 sayılı feder al resmi gazete’nin ii. bölümü  [bgbl. ii]) ve bunların kendi tüzel kişiliklerine sahip parçalar ı varlıklarını korurlar. bunlar, 13   bu federal yasanın 9. veya 16. maddesi hükümleri doğrultusunda kurulmuş din  topluluklarıdır. bu yasanın yürürlüğe girmesine müteakip on dört gün içeri sinde, 3.  madde 1. fıkra gereğince, bu federal yasanın yürürlüğe girdiği gün iti bariyle bu federal  yasa hükümlerine göre kurulmuş din toplulukları olduklarını tespit ede n yönetmelikler  çıkarılmalıdır.   (2) topluluk ve cemaat tüzükleri geçerliklerini ve seçimle belirlenen organlar görevlerini  korurlar.  bunlar 31 aralık 2015 tarihine kadar, bu federal ya sa ile uyumlu hale  getirilmelidir. tüzüklerde yapılan bu değişiklikler hakkında fede ral başbakan en geç 1  mart 2016 tarihine kadar karar vermelidir.   (3) bu yasa hükümlerine göre kurulmuş bir din topluluğunun dinî öğretilerini  yayma  amacı güden ve bu yasa yürürlüğe girdiği tarihte mevcut olan dernekle r - eğer dernek  amacı bu yasanın gerekliliklerine uyumlaştırılmamış ise - 3 1.12.2015 tarihine kadar  i̇çişleri bakanlığının kararı ile lağvedilmelidir.   (4) bu federal yasanın yürürlüğe girdiği tarihteki muvazzaf dinî y etkililer, 6.  madde 2.  fıkra hükümleri istisna tutularak, görevlerini bu federal yasa nın yürürlüğe girdiği tarihten  itibaren bir yıla kadar daha ifa edebilir.   meriyet ve i̇lga   madde 32 – yasa, federal resmi gazetede yayımlandığı günün bitimi yle yürürlüğe girer.  bu federal yasanın yürürlüğe girmesiyle birlikte ‘i̇slâm mensuplar ının bir din topluluğu  olarak tanınması hakkında kanun’ (159/1912 sayılı i̇mparatorluk  resmi gazetesi,  144/1988 sayılı federal resmi gazetesi metni; en son 2014  federal bakanlıklar kanunu  ile değiştirilmiştir, 11/2014 sayılı federal resmi gaz ete’nin i. bölümü) yürürlükten kalkar.   yürütme hükmü   madde 33 – eğer münferit düzenlemeler çerçevesinde bir federal bakanın sorumluluk  alanına girmiyor ise, bu federal yasanın yürütmesinden federal başb akan sorumludur.  '"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "812142b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "swa_1 = pdf_content.split() \n",
    "filtered_words = [word for word in swa_1 if word not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "826ab582",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_count(words):\n",
    "    counts = dict()\n",
    "    for word in words:\n",
    "        if word in counts:\n",
    "            counts[word] += 1\n",
    "        else:\n",
    "            counts[word] = 1\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6c69c37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_fre = word_count(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e4b0f0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_word_count_in_pdf = sorted(word_fre.items(), key=lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "84297283",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Security-35', 'Information-10', 'Cyber/IT-30', 'National-5', 'Act-3']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequency_keys = [i for i in df['word_frequency_count'].tolist() if str(i) != 'nan']\n",
    "frequency_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "be4e0ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------else-------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"-----------------------------------else-------------------------------\")\n",
    "\n",
    "df = pd.read_excel(\"Regulator.xlsx\", sheet_name='keywords')\n",
    "keyword_list = [i for i in df['content_keywords'].tolist() if str(i) != 'nan']\n",
    "\n",
    "basic_pdf_keywords = [i for i in df['pdf_basic_keyword'].tolist() if str(i) != 'nan'] \n",
    "\n",
    "##pdf link\n",
    "headers = { 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36' } \n",
    "pdf_link=' https://www.digitalhealth.gov.au/sites/default/files/2020-10/Annual_Report_Australian_Digital_Health_Agency_2017-2018_Online.pdf'\n",
    "response = requests.get(pdf_link, headers = headers)\n",
    "my_raw_data = response.content\n",
    "pdf_content = ''\n",
    "\n",
    "with BytesIO(my_raw_data) as data:\n",
    "    read_pdf = PyPDF2.PdfReader(data)\n",
    "    pages_text1 = read_pdf.pages[0].extract_text()\n",
    "    pages_text2 = read_pdf.pages[1].extract_text()\n",
    "    # print(\"pages text >>>>>>>>>. \",pages_text)\n",
    "    for page in range(len(read_pdf.pages)):\n",
    "        each_page_content = read_pdf.pages[page].extract_text()\n",
    "        text = each_page_content.replace(\"\\n\",' ').lower()\n",
    "        pdf_content += text\n",
    "\n",
    "swa_1 = pdf_content.split()           \n",
    "filtered_words = [word for word in swa_1 if word not in stopwords.words('english')]\n",
    "word_fre = word_count(filtered_words)        \n",
    "sorted_word_count_in_pdf = sorted(word_fre.items(), key=lambda x:x[1], reverse=True)\n",
    "# print(\"sorted_word_count_in_pdf\",sorted_word_count_in_pdf)\n",
    "\n",
    "## pdf path\n",
    "## filter 1.\n",
    "frequency_keys = [i for i in df['word_frequency_count'].tolist() if str(i) != 'nan']\n",
    "y = []\n",
    "for i in frequency_keys:\n",
    "    x = i.lower().split(\"-\")\n",
    "    if '/' in x[0]:\n",
    "        w1 = x[0].split(\"/\")[0]\n",
    "        w2 = x[0].split(\"/\")[1]\n",
    "        c = x[1]\n",
    "        y1 = [w1 for i in sorted_word_count_in_pdf if ((w1 in i[0] or w2 in i[0]) and (i[1] >= int(c)))]\n",
    "        if len(y1)==0:\n",
    "            continue\n",
    "        y.append(y1[0])\n",
    "    else:\n",
    "        w = x[0]\n",
    "        c = x[1]\n",
    "        y2 = [w for i in sorted_word_count_in_pdf if ((w in i[0]) and (i[1] >= int(c)))]\n",
    "        if len(y2)==0:\n",
    "            continue\n",
    "        y.append(y2[0])\n",
    "\n",
    "if len(y) == 5:\n",
    "        filter_1 = True\n",
    "        print(\"filter 1 pass\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2f76397f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "basic count :  7\n",
      "filter 2 pass\n"
     ]
    }
   ],
   "source": [
    " ## filter 2.\n",
    "basic_count = 0\n",
    "for j in basic_pdf_keywords:            \n",
    "    for i in set(filtered_words):\n",
    "        if j == i:\n",
    "            basic_count +=1\n",
    "print(\"basic count : \",basic_count)\n",
    "if basic_count >= 6:   # 9\n",
    "    filter_2 = True\n",
    "    print(\"filter 2 pass\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "24c590cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filter 3 pass\n"
     ]
    }
   ],
   "source": [
    "year_list = ['2015','2016','2017','2018','2019','2020','2021','2022','2023','2024','2025','2026','2027','2028','2029','2030','2031','2032','2033','2034','2035','2036','2037']\n",
    "yearcounts = dict()\n",
    "for j in year_list:            \n",
    "    for i in (set(filtered_words)):\n",
    "        if j in i:\n",
    "            if j in yearcounts:\n",
    "                yearcounts[j] += 1\n",
    "            else:\n",
    "                yearcounts[j] = 1\n",
    "\n",
    "# print(\"count >> \",yearcounts)\n",
    "\n",
    "if len(yearcounts) >= 2:\n",
    "    filter_3 = True\n",
    "    print(\"filter 3 pass\")\n",
    "if len(yearcounts) == 1:\n",
    "    if int(list(yearcounts.keys())[0]) >= 2020:\n",
    "        filter_3 = True\n",
    "        print(\"filter 3 pass\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "24be41a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filter 4 pass\n"
     ]
    }
   ],
   "source": [
    "match_keywords = [i for i in keyword_list if (i.lower().replace(' ','') in pdf_content.replace(\" \",''))]\n",
    "if len(match_keywords) >= 15:\n",
    "    filter_4 = True\n",
    "    print(\"filter 4 pass\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "19a44df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filter_5 pass\n"
     ]
    }
   ],
   "source": [
    "country_name='singapore'\n",
    "ucountry_name = country_name.replace(' ','').lower()\n",
    "if ucountry_name in pdf_content.replace(\" \",''):\n",
    "    filter_5 = True\n",
    "    print(\"filter_5 pass\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a0625de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------else-------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 21\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# print(\"pages text >>>>>>>>>. \",pages_text)\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m page \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(read_pdf\u001b[38;5;241m.\u001b[39mpages)):\n\u001b[1;32m---> 21\u001b[0m     each_page_content \u001b[38;5;241m=\u001b[39m \u001b[43mread_pdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpages\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpage\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m     text \u001b[38;5;241m=\u001b[39m each_page_content\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mlower()\n\u001b[0;32m     23\u001b[0m     pdf_content \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m text\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\PyPDF2\\_page.py:1851\u001b[0m, in \u001b[0;36mPageObject.extract_text\u001b[1;34m(self, Tj_sep, TJ_sep, orientations, space_width, visitor_operand_before, visitor_operand_after, visitor_text, *args)\u001b[0m\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(orientations, \u001b[38;5;28mint\u001b[39m):\n\u001b[0;32m   1849\u001b[0m     orientations \u001b[38;5;241m=\u001b[39m (orientations,)\n\u001b[1;32m-> 1851\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extract_text\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1852\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1853\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1854\u001b[0m \u001b[43m    \u001b[49m\u001b[43morientations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1855\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspace_width\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1856\u001b[0m \u001b[43m    \u001b[49m\u001b[43mPG\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCONTENTS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1857\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvisitor_operand_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1858\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvisitor_operand_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1859\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvisitor_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1860\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\PyPDF2\\_page.py:1737\u001b[0m, in \u001b[0;36mPageObject._extract_text\u001b[1;34m(self, obj, pdf, orientations, space_width, content_key, visitor_operand_before, visitor_operand_after, visitor_text)\u001b[0m\n\u001b[0;32m   1734\u001b[0m xobj \u001b[38;5;241m=\u001b[39m resources_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/XObject\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m xobj[operands[\u001b[38;5;241m0\u001b[39m]][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Subtype\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Image\u001b[39m\u001b[38;5;124m\"\u001b[39m:  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m   1736\u001b[0m     \u001b[38;5;66;03m# output += text\u001b[39;00m\n\u001b[1;32m-> 1737\u001b[0m     text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_xform_text\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1738\u001b[0m \u001b[43m        \u001b[49m\u001b[43mxobj\u001b[49m\u001b[43m[\u001b[49m\u001b[43moperands\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[0;32m   1739\u001b[0m \u001b[43m        \u001b[49m\u001b[43morientations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1740\u001b[0m \u001b[43m        \u001b[49m\u001b[43mspace_width\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1741\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvisitor_operand_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1742\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvisitor_operand_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1743\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvisitor_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1744\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1745\u001b[0m     output \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m text\n\u001b[0;32m   1746\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m visitor_text \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\PyPDF2\\_page.py:1880\u001b[0m, in \u001b[0;36mPageObject.extract_xform_text\u001b[1;34m(self, xform, orientations, space_width, visitor_operand_before, visitor_operand_after, visitor_text)\u001b[0m\n\u001b[0;32m   1862\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_xform_text\u001b[39m(\n\u001b[0;32m   1863\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1864\u001b[0m     xform: EncodedStreamObject,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1869\u001b[0m     visitor_text: Optional[Callable[[Any, Any, Any, Any, Any], \u001b[38;5;28;01mNone\u001b[39;00m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1870\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m   1871\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1872\u001b[0m \u001b[38;5;124;03m    Extract text from an XObject.\u001b[39;00m\n\u001b[0;32m   1873\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1878\u001b[0m \u001b[38;5;124;03m        The extracted text\u001b[39;00m\n\u001b[0;32m   1879\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1880\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extract_text\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m        \u001b[49m\u001b[43mxform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m        \u001b[49m\u001b[43morientations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m        \u001b[49m\u001b[43mspace_width\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvisitor_operand_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvisitor_operand_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvisitor_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\PyPDF2\\_page.py:1356\u001b[0m, in \u001b[0;36mPageObject._extract_text\u001b[1;34m(self, obj, pdf, orientations, space_width, content_key, visitor_operand_before, visitor_operand_after, visitor_text)\u001b[0m\n\u001b[0;32m   1352\u001b[0m     content \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1353\u001b[0m         obj[content_key]\u001b[38;5;241m.\u001b[39mget_object() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(content_key, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m obj\n\u001b[0;32m   1354\u001b[0m     )\n\u001b[0;32m   1355\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(content, ContentStream):\n\u001b[1;32m-> 1356\u001b[0m         content \u001b[38;5;241m=\u001b[39m \u001b[43mContentStream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbytes\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1357\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:  \u001b[38;5;66;03m# it means no content can be extracted(certainly empty page)\u001b[39;00m\n\u001b[0;32m   1358\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\PyPDF2\\generic\\_data_structures.py:877\u001b[0m, in \u001b[0;36mContentStream.__init__\u001b[1;34m(self, stream, pdf, forced_encoding)\u001b[0m\n\u001b[0;32m    875\u001b[0m     stream_bytes \u001b[38;5;241m=\u001b[39m BytesIO(stream_data_bytes)\n\u001b[0;32m    876\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforced_encoding \u001b[38;5;241m=\u001b[39m forced_encoding\n\u001b[1;32m--> 877\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__parse_content_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstream_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\PyPDF2\\generic\\_data_structures.py:943\u001b[0m, in \u001b[0;36mContentStream.__parse_content_stream\u001b[1;34m(self, stream)\u001b[0m\n\u001b[0;32m    941\u001b[0m         peek \u001b[38;5;241m=\u001b[39m stream\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    942\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 943\u001b[0m     operands\u001b[38;5;241m.\u001b[39mappend(\u001b[43mread_object\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforced_encoding\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\PyPDF2\\generic\\_data_structures.py:1077\u001b[0m, in \u001b[0;36mread_object\u001b[1;34m(stream, pdf, forced_encoding)\u001b[0m\n\u001b[0;32m   1075\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m IndirectObject\u001b[38;5;241m.\u001b[39mread_from_stream(stream, pdf)\n\u001b[0;32m   1076\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1077\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mNumberObject\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_from_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1078\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1079\u001b[0m     stream\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\PyPDF2\\generic\\_base.py:407\u001b[0m, in \u001b[0;36mNumberObject.read_from_stream\u001b[1;34m(stream)\u001b[0m\n\u001b[0;32m    405\u001b[0m num \u001b[38;5;241m=\u001b[39m read_until_regex(stream, NumberObject\u001b[38;5;241m.\u001b[39mNumberPattern)\n\u001b[0;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 407\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFloatObject\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    408\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m NumberObject(num)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\PyPDF2\\generic\\_base.py:330\u001b[0m, in \u001b[0;36mFloatObject.__new__\u001b[1;34m(cls, value, context)\u001b[0m\n\u001b[0;32m    326\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__new__\u001b[39m(\n\u001b[0;32m    327\u001b[0m     \u001b[38;5;28mcls\u001b[39m, value: Union[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m\"\u001b[39m, context: Optional[Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    328\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFloatObject\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    329\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 330\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m decimal\u001b[38;5;241m.\u001b[39mDecimal\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__new__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, str_(value), context)\n\u001b[0;32m    331\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    332\u001b[0m         \u001b[38;5;66;03m# If this isn't a valid decimal (happens in malformed PDFs)\u001b[39;00m\n\u001b[0;32m    333\u001b[0m         \u001b[38;5;66;03m# fallback to 0\u001b[39;00m\n\u001b[0;32m    334\u001b[0m         logger_warning(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFloatObject (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) invalid; use 0.0 instead\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;18m__name__\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"-----------------------------------else-------------------------------\")\n",
    "\n",
    "df = pd.read_excel(\"Regulator.xlsx\", sheet_name='keywords')\n",
    "keyword_list = [i for i in df['content_keywords'].tolist() if str(i) != 'nan']\n",
    "\n",
    "basic_pdf_keywords = [i for i in df['pdf_basic_keyword'].tolist() if str(i) != 'nan'] \n",
    "\n",
    "##pdf link\n",
    "headers = { 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36' } \n",
    "pdf_link=' https://www.digitalhealth.gov.au/sites/default/files/2020-10/Annual_Report_Australian_Digital_Health_Agency_2017-2018_Online.pdf'\n",
    "response = requests.get(pdf_link, headers = headers)\n",
    "my_raw_data = response.content\n",
    "pdf_content = ''\n",
    "\n",
    "with BytesIO(my_raw_data) as data:\n",
    "    read_pdf = PyPDF2.PdfReader(data)\n",
    "    pages_text1 = read_pdf.pages[0].extract_text()\n",
    "    pages_text2 = read_pdf.pages[1].extract_text()\n",
    "    # print(\"pages text >>>>>>>>>. \",pages_text)\n",
    "    for page in range(len(read_pdf.pages)):\n",
    "        each_page_content = read_pdf.pages[page].extract_text()\n",
    "        text = each_page_content.replace(\"\\n\",' ').lower()\n",
    "        pdf_content += text\n",
    "\n",
    "swa_1 = pdf_content.split()           \n",
    "filtered_words = [word for word in swa_1 if word not in stopwords.words('english')]\n",
    "word_fre = word_count(filtered_words)        \n",
    "sorted_word_count_in_pdf = sorted(word_fre.items(), key=lambda x:x[1], reverse=True)\n",
    "# print(\"sorted_word_count_in_pdf\",sorted_word_count_in_pdf)\n",
    "\n",
    "## pdf path\n",
    "\n",
    "\n",
    "## filter 1.\n",
    "frequency_keys = [i for i in df['word_frequency_count'].tolist() if str(i) != 'nan']\n",
    "y = []\n",
    "for i in frequency_keys:\n",
    "    x = i.lower().split(\"-\")\n",
    "    if '/' in x[0]:\n",
    "        w1 = x[0].split(\"/\")[0]\n",
    "        w2 = x[0].split(\"/\")[1]\n",
    "        c = x[1]\n",
    "        y1 = [w1 for i in sorted_word_count_in_pdf if ((w1 in i[0] or w2 in i[0]) and (i[1] >= int(c)))]\n",
    "        if len(y1)==0:\n",
    "            continue\n",
    "        y.append(y1[0])\n",
    "    else:\n",
    "        w = x[0]\n",
    "        c = x[1]\n",
    "        y2 = [i for i in sorted_word_count_in_pdf if ((w in i[0]) and (i[1] >= int(c)))]\n",
    "        if len(y2)==0:\n",
    "            continue\n",
    "        y.append(y2[0])\n",
    "\n",
    "if len(y) == 5:\n",
    "    filter_1 = True\n",
    "    print(\"filter 1 pass\")\n",
    "\n",
    "## filter 2.\n",
    "basic_count = 0\n",
    "for j in basic_pdf_keywords:            \n",
    "    for i in set(filtered_words):\n",
    "        if j == i:\n",
    "            basic_count +=1\n",
    "print(\"basic count : \",basic_count)\n",
    "if basic_count >= 6:   # 9\n",
    "    filter_2 = True\n",
    "    print(\"filter 2 pass\")\n",
    "\n",
    "## filter 3.\n",
    "year_list = ['2015','2016','2017','2018','2019','2020','2021','2022','2023','2024','2025','2026','2027','2028','2029','2030','2031','2032','2033','2034','2035','2036','2037']\n",
    "yearcounts = dict()\n",
    "for j in year_list:            \n",
    "    for i in set(filtered_words):\n",
    "        if j in i:                    \n",
    "            if j in yearcounts:\n",
    "                yearcounts[j] += 1\n",
    "            else:\n",
    "                yearcounts[j] = 1\n",
    "\n",
    "# print(\"count >> \",yearcounts)\n",
    "\n",
    "if len(yearcounts) >= 2:\n",
    "    filter_3 = True\n",
    "    print(\"filter 3 pass\")\n",
    "if len(yearcounts) == 1:\n",
    "    if int(list(yearcounts.keys())[0]) >= 2020:\n",
    "        filter_3 = True\n",
    "        print(\"filter 3 pass\")\n",
    "\n",
    "##filter 4.\n",
    "match_keywords = [i for i in keyword_list if (i.lower().replace(' ','') in pdf_content.replace(\" \",''))]\n",
    "if len(match_keywords) >= 15:\n",
    "    filter_4 = True\n",
    "    print(\"filter 4 pass\")\n",
    "\n",
    "##filter 5.\n",
    "ucountry_name = country_name.replace(' ','').lower()\n",
    "if ucountry_name in pdf_content.replace(\" \",''):\n",
    "    filter_5 = True\n",
    "    print(\"filter_5 pass\")\n",
    "\n",
    "\n",
    "### if all filtering conditions are satisfied then download this pdf.\n",
    "download_pdf_name=''\n",
    "if filter_1 and filter_2 and filter_3 and filter_4 and filter_5:\n",
    "    try:                   \n",
    "        cat_name = category_selection1(pages_text1.strip())\n",
    "        #DEBUG: Check cat_name element\n",
    "        if len(pages_text1.strip()) == 0:\n",
    "            cat_name = category_selection1((pages_text2.strip())[:100])\n",
    "    except:\n",
    "        cat_name = category_selection2(sorted_word_count_in_pdf)\n",
    "    print(\"cat_name : \",cat_name)\n",
    "    cat_val = pdf_score(cat_name,sorted_word_count_in_pdf)\n",
    "    # if cat_val > 350:\n",
    "    download_pdf_name = download_pdf_and_save_folder(pdf_link,folder,cat_name,cat_val)\n",
    "    data=[country_name,download_pdf_name[0],download_pdf_name[1],pdf_link]\n",
    "    with open(\"pdf_log.csv\", \"a\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecea991",
   "metadata": {},
   "source": [
    "another try\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334116d8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "filter_1 = False\n",
    "filter_2 = False\n",
    "filter_3 = False\n",
    "filter_4 = False\n",
    "filter_5 = False\n",
    "\n",
    "pdf_name = pdf_link.split(\"/\")[-1]\n",
    "print(\"-----------------------------------else-------------------------------\")\n",
    "\n",
    "df = pd.read_excel(\"Regulator.xlsx\", sheet_name='keywords')\n",
    "keyword_list = [i for i in df['content_keywords'].tolist() if str(i) != 'nan']\n",
    "\n",
    "basic_pdf_keywords = [i for i in df['pdf_basic_keyword'].tolist() if str(i) != 'nan'] \n",
    "\n",
    "##pdf link\n",
    "headers = { 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36' } \n",
    "time.sleep(0.01)\n",
    "response = requests.get(pdf_link, headers = headers)\n",
    "my_raw_data = response.content\n",
    "pdf_content = ''\n",
    "\n",
    "with BytesIO(my_raw_data) as data:\n",
    "    read_pdf = PyPDF2.PdfReader(data)\n",
    "    pages_text1 = read_pdf.pages[0].extract_text()\n",
    "    pages_text2 = read_pdf.pages[1].extract_text()\n",
    "    # print(\"pages text >>>>>>>>>. \",pages_text)\n",
    "    for page in range(len(read_pdf.pages)):\n",
    "        each_page_content = read_pdf.pages[page].extract_text()\n",
    "        text = each_page_content.replace(\"\\n\",' ').lower()\n",
    "        pdf_content += text\n",
    "\n",
    "swa_1 = pdf_content.split()           \n",
    "filtered_words = [word for word in swa_1 if word not in stopwords.words('english')]\n",
    "word_fre = word_count(filtered_words)        \n",
    "sorted_word_count_in_pdf = sorted(word_fre.items(), key=lambda x:x[1], reverse=True)\n",
    "# print(\"sorted_word_count_in_pdf\",sorted_word_count_in_pdf)\n",
    "\n",
    "## pdf path\n",
    "\n",
    "\n",
    "## filter 1.\n",
    "frequency_keys = [i for i in df['word_frequency_count'].tolist() if str(i) != 'nan']\n",
    "y = []\n",
    "for i in frequency_keys:\n",
    "    x = i.lower().split(\"-\")\n",
    "    if '/' in x[0]:\n",
    "        w1 = x[0].split(\"/\")[0]\n",
    "        w2 = x[0].split(\"/\")[1]\n",
    "        c = x[1]\n",
    "        y1 = [w1 for i in sorted_word_count_in_pdf if ((w1 in i[0] or w2 in i[0]) and (i[1] >= int(c)))]\n",
    "        if len(y1)==0:\n",
    "            continue\n",
    "        y.append(y1[0])\n",
    "    else:\n",
    "        w = x[0]\n",
    "        c = x[1]\n",
    "        y2 = [w for i in sorted_word_count_in_pdf if ((w in i[0]) and (i[1] >= int(c)))]\n",
    "        if len(y2)==0:\n",
    "            continue\n",
    "        y.append(y2[0])\n",
    "\n",
    "if len(y) == 5:\n",
    "    filter_1 = True\n",
    "    print(\"filter 1 pass\")\n",
    "\n",
    "## filter 2.\n",
    "basic_count = 0\n",
    "for j in basic_pdf_keywords:            \n",
    "    for i in set(filtered_words):\n",
    "        if j == i:\n",
    "            basic_count +=1\n",
    "print(\"basic count : \",basic_count)\n",
    "if basic_count >= 6:   # 9\n",
    "    filter_2 = True\n",
    "    print(\"filter 2 pass\")\n",
    "\n",
    "## filter 3.\n",
    "year_list = ['2015','2016','2017','2018','2019','2020','2021','2022','2023','2024','2025','2026','2027','2028','2029','2030','2031','2032','2033','2034','2035','2036','2037']\n",
    "yearcounts = dict()\n",
    "for j in year_list:            \n",
    "    for i in set(filtered_words):\n",
    "        if j in i:                    \n",
    "            if j in yearcounts:\n",
    "                yearcounts[j] += 1\n",
    "            else:\n",
    "                yearcounts[j] = 1\n",
    "\n",
    "# print(\"count >> \",yearcounts)\n",
    "\n",
    "if len(yearcounts) >= 2:\n",
    "    filter_3 = True\n",
    "    print(\"filter 3 pass\")\n",
    "if len(yearcounts) == 1:\n",
    "    if int(list(yearcounts.keys())[0]) >= 2020:\n",
    "        filter_3 = True\n",
    "        print(\"filter 3 pass\")\n",
    "\n",
    "##filter 4.\n",
    "match_keywords = [i for i in keyword_list if (i.lower().replace(' ','') in pdf_content.replace(\" \",''))]\n",
    "if len(match_keywords) >= 15:\n",
    "    filter_4 = True\n",
    "    print(\"filter 4 pass\")\n",
    "\n",
    "##filter 5.\n",
    "ucountry_name = country_name.replace(' ','').lower()\n",
    "if ucountry_name in pdf_content.replace(\" \",''):\n",
    "    filter_5 = True\n",
    "    print(\"filter_5 pass\")\n",
    "\n",
    "download_pdf_name=''\n",
    "if filter_1 and filter_2 and filter_3 and filter_4 and filter_5:\n",
    "    print('cool')\n",
    "else:\n",
    "    print('else')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05549c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_word_count_in_pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963ac4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y2 = [w for i in sorted_word_count_in_pdf if ((w in i[0]) and (i[1] >= int(c)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff77576",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35000bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def category_selection1(pages_text):\n",
    "    if len(pages_text.strip()) != 0:\n",
    "        for line in io.StringIO(pages_text):\n",
    "            if 'strateg' in line.lower():\n",
    "                cat_name = \"strategy\"\n",
    "            elif 'polic' in line.lower():\n",
    "                cat_name = 'policy'\n",
    "            elif ('guidelines' in line.lower() or 'guide' in line.lower()):\n",
    "                cat_name = 'guildlines'\n",
    "        return cat_name\n",
    "    else:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7988a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def category_selection2(x):\n",
    "    catagory_name = 0\n",
    "    keywords = ['strateg','polic','guidline']\n",
    "    my_dict = {}\n",
    "    for i in keywords:\n",
    "        y = [j for j in x if i in j[0]]\n",
    "        result = sum(tup[1] for tup in y)\n",
    "        my_dict[i] = result\n",
    "    print(\"my_dict : \",my_dict)\n",
    "    s = len(set(my_dict.values()))\n",
    "    if s>2:\n",
    "        cat_name = max(my_dict, key=my_dict.get)\n",
    "        cat_val = max(my_dict.values())\n",
    "        if cat_val >= 20:\n",
    "            catagory_name = 'policy' if cat_name == 'polic' else \"strategy\" if cat_name == 'strateg' else 'guildlines' \n",
    "    return catagory_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca326d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_score(cat_name,sorted_word_count_in_pdf):\n",
    "    df = pd.read_excel(\"Regulator.xlsx\", sheet_name='scoring')\n",
    "    if cat_name == 'policy':\n",
    "        colum_name = 'cyber_security_policy'\n",
    "    if cat_name == 'strategy':\n",
    "        colum_name = 'Cyber_security_strategy'\n",
    "    if cat_name == 'guildlines':\n",
    "        colum_name = 'Cyber_security_guidelines'\n",
    "\n",
    "    score_keyword = [i for i in df[colum_name].tolist() if str(i) != 'nan']\n",
    "    print(score_keyword)\n",
    "\n",
    "    total_score = 0\n",
    "    for i in score_keyword:\n",
    "        y = i.split('-')\n",
    "        word = y[0].lower()\n",
    "        weight = y[1]\n",
    "        for j in sorted_word_count_in_pdf:  \n",
    "            if word == j[0]:\n",
    "                frequency = j[1]\n",
    "                sub_score = int(weight) * int(frequency)\n",
    "                total_score += sub_score\n",
    "    return total_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0557b7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_pdf_and_save_folder(pdf_link,folder,cat_name,cat_val):\n",
    "\n",
    "    # print(\"download pdf link  ---------------- >>>> \",pdf_link)\n",
    "    # logging.info(f\"download pdf link : {pdf_link}\")  #change 1\n",
    "\n",
    "    current_time = datetime.datetime.now()\n",
    "    time = str(current_time).replace(\" \",'_')\n",
    "    print(\"time >> \",time)\n",
    "\n",
    "    headers = { 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36' } \n",
    "    response = requests.get(pdf_link, headers = headers)\n",
    "    pdf_name = pdf_link.split(\"/\")[-1]\n",
    "    pdf_name = pdf_name.split(\".\")\n",
    "    # print(\"pdf_name --------->>>>>> \",pdf_name)\n",
    "    \n",
    "\n",
    "    if cat_name != 0:\n",
    "        cat_folder = f\"{folder}\"\n",
    "        if not os.path.exists(cat_folder):\n",
    "            os.makedirs(cat_folder)\n",
    "        file = open(f\"{folder}/{pdf_name[0]}.pdf\", \"wb\")\n",
    "    else:\n",
    "        file = open(f\"{folder}/{pdf_name[0]}\", \"wb\")\n",
    "    \n",
    "    file.write(response.content)\n",
    "    file.close()\n",
    "    return pdf_name\n",
    "\n",
    "\n",
    "def pdf_existance_check(pdf_dir,pdf_name):\n",
    "    pdf_file = []\n",
    "    for dirpath, dirnames, filenames in os.walk(pdf_dir):\n",
    "        for filename in [f for f in filenames if f.endswith(\".pdf\")]:\n",
    "            pdf_file.append(filename)\n",
    "    indicator = any(pdf_name in x  for x in pdf_file)   \n",
    "    return indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e909ae1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "folder='E:\\Infoware\\CyberSecurityDeployment'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce541c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:                   \n",
    "    cat_name = category_selection1(pages_text1.strip())\n",
    "    #DEBUG: Check cat_name element\n",
    "    if len(pages_text1.strip()) == 0:\n",
    "        cat_name = category_selection1((pages_text2.strip())[:100])\n",
    "except:\n",
    "    cat_name = category_selection2(sorted_word_count_in_pdf)\n",
    "print(\"cat_name : \",cat_name)\n",
    "cat_val = pdf_score(cat_name,sorted_word_count_in_pdf)\n",
    "# if cat_val > 350:\n",
    "download_pdf_name = download_pdf_and_save_folder(pdf_link,folder,cat_name,cat_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740f10db",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_name = pdf_link.split(\"/\")[-1]\n",
    "pdf_name = pdf_name.split(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e708016",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d57379",
   "metadata": {},
   "outputs": [],
   "source": [
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab840e4",
   "metadata": {},
   "source": [
    "## Old function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc02621f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_pdf_and_save_folder(pdf_link,folder,cat_name,cat_val):\n",
    "\n",
    "    # print(\"download pdf link  ---------------- >>>> \",pdf_link)\n",
    "    # logging.info(f\"download pdf link : {pdf_link}\")  #change 1\n",
    "\n",
    "    current_time = datetime.datetime.now()\n",
    "    time = str(current_time).replace(\" \",'_')\n",
    "    print(\"time >> \",time)\n",
    "\n",
    "    headers = { 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36' } \n",
    "    response = requests.get(pdf_link, headers = headers)\n",
    "    pdf_name = pdf_link.split(\"/\")[-1]\n",
    "    pdf_name = pdf_name.split(\".\")\n",
    "    # print(\"pdf_name --------->>>>>> \",pdf_name)\n",
    "\n",
    "    # logging.info(f\"pdf_name : {pdf_name}\")  #change 1\n",
    "    if cat_name != 0:\n",
    "        file = open(f\"{folder}/{cat_name}/{pdf_name[0]}.pdf\", \"wb\")\n",
    "    else:\n",
    "        file = open(f\"{folder}/{pdf_name}\", \"wb\")\n",
    "    file.write(response.content)\n",
    "    file.close()\n",
    "    return pdf_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae95aa81",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_pdf_name = download_pdf_and_save_folder(pdf_link,folder,cat_name,cat_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bb77ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4369e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d93f9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import pandas as pd\n",
    "import string\n",
    "import requests\n",
    "import time \n",
    "from datetime import date\n",
    "from duplicate_text_extractor_from_link import *\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from pdf_selector_update1 import *\n",
    "import pytz\n",
    "import csv\n",
    "\n",
    "from googlesearch import search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad092fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extension_for_url(country):\n",
    "    df = pd.read_csv(\"WebScrap.csv\")\n",
    "    key =[]\n",
    "    for i in df['Country']:\n",
    "        if country.replace(\" \",'').lower() in i.lower().replace(\" \",''):\n",
    "            x = (df.loc[(df['Country'] == i )]).values.tolist()\n",
    "            url_kwy = [i for i in x[0][1:] if str(i) != 'nan']\n",
    "            key += url_kwy\n",
    "    ke = list(set(key))\n",
    "    return ke\n",
    "\n",
    "def filter1(links,country_name):  \n",
    "    https_links = [link for link in links if 'https://' in link.lower()] \n",
    "    authentic_site_extension = extension_for_url(country_name)\n",
    "    print(\"extension name : \",authentic_site_extension)\n",
    "    com_ex = ['.gov','.org','.eu','itu']\n",
    "    c_ex = [i for i in authentic_site_extension if i not in com_ex]\n",
    "    \n",
    "    first_stage_filter = [link for i in authentic_site_extension for link in https_links if i.lower() in link.lower()]\n",
    "    first_stage_filter = https_links if len(first_stage_filter) == 0 else first_stage_filter\n",
    "    filter1_links = list(set(first_stage_filter))\n",
    "    return filter1_links,c_ex\n",
    "\n",
    "def filter_sublinks(sublink_list,main_extension):\n",
    "    df = pd.read_excel(\"Regulator.xlsx\", sheet_name='keywords')\n",
    "    keyword_list = [i for i in df['Url_keywords'].tolist() if str(i) != 'nan']\n",
    "    filter2_sublinks = []\n",
    "    for keyword in keyword_list:\n",
    "        y = keyword.translate(str.maketrans('', '', string.punctuation))\n",
    "        for each_sublink in sublink_list:\n",
    "            if main_extension in each_sublink:\n",
    "                 filter2_sublinks.append(each_sublink)            \n",
    "            x = each_sublink.translate(str.maketrans('', '', string.punctuation))\n",
    "            if y.lower() in x.lower():\n",
    "                filter2_sublinks.append(each_sublink)\n",
    "    filter2_sublinks = list(set(filter2_sublinks))\n",
    "    return filter2_sublinks\n",
    "\n",
    "def filter3(link_list): \n",
    "    l = ['linkedin','facebook','twitter','youtube','instagram','wiki','contact','yahoo','whatsapp','login','signin','unodc','cyberwiser.eu']\n",
    "    q = [link for link in link_list if any(ext in link for ext in l)]\n",
    "    links = [i for i in link_list if i not in q]\n",
    "    return links\n",
    "\n",
    "\n",
    "\n",
    "def find_site_name(x):\n",
    "    site_name = [j for j in x.split(\"/\") if 'www' in j]\n",
    "    return site_name\n",
    "\n",
    "def unique_filter_links(list_of_links):\n",
    "    un_web_site = []\n",
    "    for i in list_of_links:\n",
    "        site_name = find_site_name(i)\n",
    "        res = any(site_name[0] in sub for sub in un_web_site)\n",
    "        if res == False:\n",
    "            un_web_site.append(i)\n",
    "    return un_web_site\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3934bfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "text_dir = 'summary.txt'\n",
    "day = ''\n",
    "headers = { 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36' } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80dbfa05",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with open(text_dir,'a') as document:\n",
    "    df = pd.read_csv('test_country.csv')\n",
    "    for cnt in range(len(df[\"Country_Name\"])):  \n",
    "        raw_links=[]\n",
    "        country_name = ''\n",
    "        user_response = df[\"Country_Name\"][cnt]                                               \n",
    "        country_name = user_response\n",
    "        user_response = \"cyber security policy/strategy in \"+user_response\n",
    "        print(\"user_responce >>> \",user_response)\n",
    "        for j in search(user_response, tld=\"co.in\", num=1, stop=10, pause=2):     ########\n",
    "            raw_links.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf7de81",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51af34d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=search(user_response, tld=\"co.in\", num=1, stop=10, pause=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68772b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter1links,c_ex = filter1(raw_links,country_name)\n",
    "filter2links = filter_sublinks(filter1links,c_ex[0])\n",
    "filter3links = filter3(filter2links)\n",
    "links = filter3links\n",
    "lunk=[0]\n",
    "lunk[0]=links[4]\n",
    "print(\"filter links >>>>>>>>>>>>>>>>>>>>>> \",links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33afbafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "lunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b5a227",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_flder = country_name.replace(\" \",\"_\")\n",
    "link_pdf = {}\n",
    "path2=main_flder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52617fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "path2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e28020",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "text_dir = 'summary.txt'\n",
    "with open(text_dir,'a') as document:\n",
    "    df = pd.read_csv('test_country.csv')\n",
    "    for link in lunk:\n",
    "        print(\"URL for policy ------------------>>>>>>> \",link)\n",
    "\n",
    "    pdf_name_list = []\n",
    "    pdf_from_sub_link = []\n",
    "    name = str(link[8:]).replace(\"/\",\"_\")\n",
    "    text_dir = f\"{path2}/{name}.txt\"\n",
    "\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36\")\n",
    "    driver = webdriver.Chrome(options=options,service=ChromeService(ChromeDriverManager().install()))\n",
    "    driver.maximize_window()\n",
    "    driver.get(link)\n",
    "    time.sleep(10)\n",
    "    current_link = driver.current_url\n",
    "\n",
    "    if 'pdf' in current_link.lower():\n",
    "        x = pdf_selector(link,path2,country_name)\n",
    "        print(\"x >>>\",x)\n",
    "        if x is not None:\n",
    "            if 'pdf' in x.lower():\n",
    "                pdf_name_list.append(x)\n",
    "                driver.quit()\n",
    "        else:\n",
    "            pass\n",
    "    else:\n",
    "\n",
    "        list_=[] \n",
    "        lnk=driver.find_elements(By.XPATH, \"//a[@href]\")\n",
    "        try:\n",
    "            for i in lnk:\n",
    "                list_.append(str(i.get_attribute('href'))) \n",
    "        except:\n",
    "            pass\n",
    "        final_list = [link]+list_\n",
    "        sublink_list = list(set(final_list))\n",
    "        driver.quit()\n",
    "\n",
    "        # print(\"raw_sublink >>> \",sublink_list)\n",
    "        print(\"sublink list :\",len(sublink_list))\n",
    "        Filter_Sublinks = filter_sublinks(sublink_list,c_ex[0])\n",
    "        u_filter_sublinks = filter3(Filter_Sublinks)\n",
    "        https_filtersublinks = [sublink for sublink in u_filter_sublinks if 'https://' in sublink.lower()]\n",
    "\n",
    "        print(\"sublinks after filter >>>>>>>>>>>>>>> \",https_filtersublinks)\n",
    "        print(\"len of filter sublink :\",len(https_filtersublinks))\n",
    "\n",
    "        pdf_from_sub_link = create_text_for_each_link(text_dir,https_filtersublinks,path2,country_name)\n",
    "\n",
    "    pdf_for_link = pdf_name_list + pdf_from_sub_link\n",
    "    print(pdf_for_link)\n",
    "    print(pdf_name_list)\n",
    "    print(pdf_from_sub_link)\n",
    "    if len(pdf_for_link)>0:\n",
    "        link_pdf[link] = pdf_for_link\n",
    "\n",
    "    print(\"-----------@----------@-----------@------------@----------@-----------@------------\")\n",
    "\n",
    "    import pytz\n",
    "\n",
    "    print(\"summary >>>>>>>>>>> \",link_pdf)\n",
    "\n",
    "    indian_tz = pytz.timezone(\"Asia/Kolkata\")\n",
    "    indian_time = datetime.datetime.now(indian_tz)\n",
    "    day = indian_time.strftime(\"%d/%m/%Y %H:%M:%S\")    \n",
    "    document.write(str(day))\n",
    "    document.write(\"\\n\\n\")\n",
    "    document.write(str(country_name))\n",
    "    document.write(\"\\n\\n\")\n",
    "    document.write(f\"Raw_link : {str(raw_links)}\")\n",
    "    document.write(\"\\n\\n\")\n",
    "    document.write(f\"filter_link : {str(links)}\")\n",
    "    document.write(\"\\n\\n\")\n",
    "    document.write(f\"pdf download summary from url : {str(link_pdf)}\")\n",
    "    document.write(\"\\n\\n\\n\\n\")\n",
    "\n",
    "\n",
    "import csv\n",
    "import datetime\n",
    "import pytz\n",
    "\n",
    "log_data = [str(country_name), str(day), str(links), str(len(links))]\n",
    "\n",
    "with open(\"logdet.csv\", \"a\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(log_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5d8e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_name='australia'\n",
    "day='30/06/2023'\n",
    "links=[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ae113f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import datetime\n",
    "import pytz\n",
    "\n",
    "log_data = [str(country_name), str(day), str(links), str(len(links))]\n",
    "\n",
    "with open(\"logdet.csv\", \"a\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(log_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af8f5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "day = indian_time.strftime(\"%d/%m/%Y %H:%M:%S\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20b3a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41baa684",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_size(file_path):\n",
    "    try:\n",
    "        size = os.path.getsize(file_path)\n",
    "        return size\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File '{file_path}' not found.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b724fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(url, save_path):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        with open(save_path, 'wb') as file:\n",
    "            file.write(response.content)\n",
    "        print(f\"Downloaded file from {url} and saved to {save_path}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while downloading: {e}\")\n",
    "\n",
    "def update_file(original_file, new_file):\n",
    "    try:\n",
    "        shutil.copy2(new_file, original_file)\n",
    "        print(f\"Updated '{original_file}' with content from '{new_file}'.\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"File not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597c99db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CSV file\n",
    "csv_file_path = \"pdf_log.csv\"\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    country = row['country']\n",
    "    file_name = row['pdf_name']\n",
    "    path = row['path']\n",
    "    link = row['link']\n",
    "    \n",
    "    existing_file_path = path\n",
    "    existing_file_size = get_file_size(existing_file_path)\n",
    "    \n",
    "    if existing_file_size is not None:\n",
    "        download_file(link, \"new_file_temp.pdf\")\n",
    "        new_file_path = \"new_file_temp.pdf\"\n",
    "        new_file_size = get_file_size(new_file_path)\n",
    "        \n",
    "        if new_file_size is not None:\n",
    "            if existing_file_size == new_file_size:\n",
    "                print(f\"No change for {country}: Sizes are the same.\")\n",
    "            else:\n",
    "                update_file(existing_file_path, new_file_path)\n",
    "        \n",
    "        try:\n",
    "            os.remove(new_file_path)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    else:\n",
    "        print(f\"Could not compare file sizes for {country}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37cf236",
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166b07b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.iterrows():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b6ac6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13be3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "time1=str(datetime.datetime.now()).split()[1][:-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4797a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "time2=str(datetime.datetime.now()).split()[1][:-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70aba812",
   "metadata": {},
   "outputs": [],
   "source": [
    "time=time2-time1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00782d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time=current[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c6e34e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99283c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time[0:-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab637860",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def parse_time(time_str):\n",
    "    return \n",
    "\n",
    "def calculate_time_taken(start_time_str, end_time_str):\n",
    "    parse=lambda time : datetime.datetime.strptime(time, '%H:%M:%S.%f')\n",
    "    start_time = parse(start_time_str)\n",
    "    end_time = parse(end_time_str)\n",
    "    time_taken = end_time - start_time\n",
    "    return time_taken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96522baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "str(calculate_time_taken(time1,time2))[:-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9d7cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_time_taken(start_time_str, end_time_str):\n",
    "    parse=lambda time : datetime.datetime.strptime(time, '%H:%M:%S.%f')\n",
    "    start_time = parse(start_time_str)\n",
    "    end_time = parse(end_time_str)\n",
    "    time_taken = end_time - start_time\n",
    "    return time_taken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba181e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(time1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c002403",
   "metadata": {},
   "outputs": [],
   "source": [
    "time2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9806c042",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
